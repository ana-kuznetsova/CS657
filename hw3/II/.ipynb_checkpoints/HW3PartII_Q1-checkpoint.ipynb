{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as snddev\n",
    "import soundfile as sndfl\n",
    "import librosa\n",
    "import os\n",
    "from collections import namedtuple\n",
    "from random import sample \n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, dev, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(file_name, target_sr):\n",
    "    sound, samplerate = sndfl.read(file_name)\n",
    "    return librosa.core.resample(sound, samplerate, target_sr)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = 'Speech Data/IEEE/IEEE_female'\n",
    "male = 'Speech Data/IEEE/IEEE_male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_dev_split(path, target_sr):\n",
    "    \n",
    "    def put_to_dir(paths, root, part, target_sr):\n",
    "        \n",
    "        for path in tqdm(paths):\n",
    "            resampled = resample(path, target_sr)\n",
    "            file_name =  os.path.split(path)[-1]\n",
    "            new_path = os.path.join(root+'_split', part)\n",
    "    \n",
    "            if os.path.exists(new_path):\n",
    "                librosa.output.write_wav(new_path + '/' + file_name, resampled, target_sr)\n",
    "            else:\n",
    "                os.makedirs(new_path)\n",
    "                librosa.output.write_wav(new_path + '/' + file_name, resampled, target_sr)\n",
    "        \n",
    "    paths = []\n",
    "    root = ''\n",
    " \n",
    "    files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            paths.append(os.path.join(root, file))\n",
    "    \n",
    "            \n",
    "    train = paths[:500]\n",
    "    dev = paths[500:600]\n",
    "    test = paths[600:700]\n",
    "    \n",
    "    put_to_dir(train, root, 'train', target_sr)\n",
    "    put_to_dir(dev, root, 'dev', target_sr)\n",
    "    put_to_dir(test, root, 'test', target_sr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:36<00:00, 13.61it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 13.51it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 13.36it/s]\n"
     ]
    }
   ],
   "source": [
    "train_test_dev_split(female, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:51<00:00,  9.69it/s]\n",
      "100%|██████████| 100/100 [00:09<00:00, 10.49it/s]\n",
      "100%|██████████| 100/100 [00:06<00:00, 14.44it/s]\n"
     ]
    }
   ],
   "source": [
    "train_test_dev_split(male, 16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librosa reads instantly with a desired SR, no resampling needed\n",
    "\n",
    "noise1 = librosa.core.load('Noise_Data/Live_Restaurant.wav', 16000)\n",
    "noise2 = librosa.core.load('Noise_Data/adtCafe.wav', 16000)\n",
    "noise3 = librosa.core.load('Noise_Data/adtBabble2.wav', 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_noise_half(noise_files):\n",
    "    \n",
    "    Data = namedtuple('Data', 'train test')\n",
    "    \n",
    "    noises_split = []\n",
    "    \n",
    "    for n in noise_files:\n",
    "        div_index = len(n)//2\n",
    "        noise_data = Data(n[:div_index], n[div_index:])\n",
    "        noises_split.append(noise_data)\n",
    "        \n",
    "    return noises_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split noise for train, dev, test sets\n",
    "noises_split = split_noise_half([noise1[0], noise2[0], noise3[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNRS = [-3, 0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy(speech, noise, desired_snr):   \n",
    "    #calculate energies\n",
    "    E_speech = np.sum(np.power(speech, 2))\n",
    "    E_noise = np.sum(np.power(noise, 2))\n",
    "    \n",
    "    #calculate b coeff\n",
    "    b = np.sqrt((E_speech/(np.power(10, (desired_snr/10))))/E_noise)    \n",
    "    return speech + b*noise\n",
    "\n",
    "def spit(file_name, signal):\n",
    "    librosa.output.write_wav(file_name, signal, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_data(noise_signals, snrs, speech_dir, output_dir):\n",
    "    \n",
    "    #generate paths to read\n",
    "    paths = []    \n",
    "    for root, dirs, files in os.walk(speech_dir):\n",
    "        for file in files:\n",
    "            paths.append(os.path.join(root, file))\n",
    "            \n",
    "    #make correspondence df\n",
    "    correspondence = {}\n",
    "                \n",
    "    for path in tqdm(paths):\n",
    "        speech = librosa.core.load(path, 16000)\n",
    "        #noise index will be used for file names\n",
    "        noise_index = 0\n",
    "        noisy_signals = []\n",
    "        for n in noise_signals:\n",
    "            noise_index+=1\n",
    "            for s in snrs:\n",
    "                # select random values from noise vector\n",
    "                noise = np.random.choice(n, size=len(speech[0]))\n",
    "                noisy_speech = generate_noisy(speech[0], noise, s)\n",
    "                file_name = os.path.split(path)[-1][:-4]+'-'+str(noise_index)+str(s)+'.wav'\n",
    "                noisy_signals.append(output_dir + '/' + file_name)\n",
    "\n",
    "                if os.path.exists(output_dir):\n",
    "                    spit(output_dir + '/' + file_name, noisy_speech)\n",
    "                else:\n",
    "                    os.makedirs(output_dir)\n",
    "                    spit(output_dir + '/' + file_name, noisy_speech)\n",
    "        correspondence[path] = '|'.join(noisy_signals)\n",
    "    return correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:25<00:00, 19.47it/s]\n"
     ]
    }
   ],
   "source": [
    "train1 = generate_train_data([n.train for n in noises_split], SNRS,\\\n",
    "                    'Speech Data/IEEE/IEEE_female_split/train/',\\\n",
    "                   'Speech Data/IEEE/train_noisy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:25<00:00, 19.88it/s]\n"
     ]
    }
   ],
   "source": [
    "train2 = generate_train_data([n.train for n in noises_split], SNRS,\\\n",
    "                    'Speech Data/IEEE/IEEE_male_split/train/',\\\n",
    "                   'Speech Data/IEEE/train_noisy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 12.67it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 17.09it/s]\n"
     ]
    }
   ],
   "source": [
    "dev1 = generate_train_data([n.train for n in noises_split], SNRS,\\\n",
    "                    'Speech Data/IEEE/IEEE_female_split/dev/',\\\n",
    "                   'Speech Data/IEEE/dev_noisy')\n",
    "\n",
    "dev2 = generate_train_data([n.train for n in noises_split], SNRS,\\\n",
    "                    'Speech Data/IEEE/IEEE_male_split/dev/',\\\n",
    "                   'Speech Data/IEEE/dev_noisy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.72it/s]\n",
      "100%|██████████| 100/100 [00:16<00:00,  6.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# select test noise data for test files\n",
    "test1 = generate_train_data([n.test for n in noises_split], SNRS,\\\n",
    "                    'Speech Data/IEEE/IEEE_female_split/test/',\\\n",
    "                   'Speech Data/IEEE/test_noisy')\n",
    "\n",
    "test2 = generate_train_data([n.test for n in noises_split], SNRS,\\\n",
    "                    'Speech Data/IEEE/IEEE_male_split/test/',\\\n",
    "                   'Speech Data/IEEE/test_noisy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.update(train2)\n",
    "dev1.update(dev2)\n",
    "test1.update(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dictionaries to pickle\n",
    "import pickle\n",
    "\n",
    "with open('train.p', 'wb') as fp:\n",
    "    pickle.dump(train1, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('dev.p', 'wb') as fp:\n",
    "    pickle.dump(dev1, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('test.p', 'wb') as fp:\n",
    "    pickle.dump(test1, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mapping_dicts/train.p', 'rb') as fp:\n",
    "    data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2. Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import torch\n",
    "import torch.nn.functional as Func\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Training Dataloader\n",
    "The input X for the DNN is a single time frame of the STFT log-magnitude response of a noisy speech signal.\n",
    "The label M for the DNN is a single time from from the corresponding STFT magnitude response of the clean speech signal.\n",
    "\n",
    "In the following sections, we first paired each noisy speech signal with its clean speech by filename and save their STFTs in .npy format for Training data. \n",
    "\n",
    "You'll need to change the data paths throughout, so that they match your file structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frame_path = 'Speech Data/IEEE/npy/train_frame/'\n",
    "\n",
    "def save_npy(paths_dict, train_frame_path):\n",
    "    #were k is the path to clean speech file\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for k in tqdm(paths_dict.keys()):\n",
    "        #make stft for the clean file\n",
    "        clean_speech, sr = librosa.load(k,sr=None)\n",
    "        stft_clean = librosa.stft(clean_speech, n_fft=512,hop_length=160,win_length=320)\n",
    "        stft_clean = 10*np.log10(np.abs(stft_clean))\n",
    "        \n",
    "        # make stfts for noisy files\n",
    "        for n in paths_dict[k].split('|'):\n",
    "            noisy_speech, sr = librosa.load(n, sr=None)\n",
    "            stft_noisy = librosa.stft(noisy_speech, n_fft=512, hop_length=160, win_length=320)\n",
    "            stft_noisy = 10*np.log10(np.abs(stft_noisy))\n",
    "            \n",
    "            for j in range(stft_clean.shape[1]):\n",
    "                Xfile = train_frame_path + 'x' + str(counter) +'.npy'\n",
    "                Mfile = train_frame_path + 'm' + str(counter) +'.npy'\n",
    "                #X is the magnitude STFT for noisy speech, M is the magnitude STFT for clean speech\n",
    "                np.save(Xfile, stft_noisy[:,j])\n",
    "                np.save(Mfile,stft_clean[:,j])\n",
    "                counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:12<1:08:16,  4.11s/it]/home/anakuz/miniconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log10\n",
      "  if sys.path[0] == '':\n",
      " 26%|██▌       | 255/1000 [11:05<32:23,  2.61s/it]ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_npy(train1, train_frame_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainDataLoader(data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.dataPath = '/N/u/anakuzne/Carbonate/dl_for_speech/\\\n",
    "        HW3_II/IEEE/npy/train_frame/'\n",
    "    def __getitem__(self, index):\n",
    "        xFile = self.dataPath + 'x' + str(index) + '.npy'\n",
    "        mFile = self.dataPath + 'm' + str(index) + '.npy'\n",
    "        X = np.load(xFile)\n",
    "        M_truth = np.load(mFile)\n",
    "        return torch.from_numpy(X),torch.from_numpy(M_truth)\n",
    "    def __len__(self):\n",
    "        #Number of files\n",
    "        return 4638636 # CORRECT THIS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class valDataLoader(data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.dataPath = '/N/u/anakuzne/Carbonate/dl_for_speech/\\\n",
    "        HW3_II/IEEE/npy/dev_frame/'\n",
    "    def __getitem__(self, index):\n",
    "        xFile = self.dataPath + 'x' + str(index) + '.npy'\n",
    "        mFile = self.dataPath + 'm' + str(index) + '.npy'\n",
    "        X = np.load(xFile)\n",
    "        M_truth = np.load(mFile)\n",
    "        return torch.from_numpy(X),torch.from_numpy(M_truth)\n",
    "    def __len__(self):\n",
    "        #Number of files\n",
    "        return 936144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/N/u/anakuzne/Carbonate/dl_for_speech/HW3_II/            IEEE/test_noisy/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-00837f95d122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtestPath\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m'\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0manakuzne\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mCarbonate\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdl_for_speech\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mHW3_II\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m             \u001b[0mIEEE\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest_noisy\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtestMixedList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtestLength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestMixedList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtestPyPath\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0manakuzne\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mCarbonate\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdl_for_speech\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/N/u/anakuzne/Carbonate/dl_for_speech/HW3_II/            IEEE/test_noisy/'"
     ]
    }
   ],
   "source": [
    "testPath = '/N/u/anakuzne/Carbonate/dl_for_speech/HW3_II/\\\n",
    "            IEEE/test_noisy/'\n",
    "testMixedList = os.listdir(testPath)\n",
    "testLength = len(testMixedList)\n",
    "testPyPath ='/N/u/anakuzne/Carbonate/dl_for_speech/\\\n",
    "        HW3_II/IEEE/npy/test_frame/'\n",
    "teList = os.listdir(testPyPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testLength' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1bcfad667c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestLength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mxFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestMixedList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestPath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mxFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testLength' is not defined"
     ]
    }
   ],
   "source": [
    "for index in range(0, testLength):\n",
    "    xFile = testMixedList[index]\n",
    "    sx, sr = librosa.load(testPath + xFile, sr=None)\n",
    "    X = librosa.stft(sx,n_fft=512,hop_length=160,win_length=320)\n",
    "    X = 10*np.log10(np.abs(X))\n",
    "    a = xFile.split('.',1)\n",
    "    Xfile = testPyPath + a[0] + '.npy'\n",
    "    np.save(Xfile, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testDataLoader(data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.dataPath = '/N/u/anakuzne/Carbonate/dl_for_speech/\\\n",
    "        HW3_II/IEEE/npy/test_frame/'\n",
    "        self.dataList = teList\n",
    "    def __getitem__(self, index):\n",
    "        xFile = self.dataPath + self.dataList[index]\n",
    "        X = np.load(xFile)\n",
    "        return torch.from_numpy(X).t()\n",
    "    def __len__(self):\n",
    "        return 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = data.DataLoader(trainDataLoader(),batch_size = 10000,shuffle=True,drop_last = True) \n",
    "valData = data.DataLoader(valDataLoader(),batch_size = 10000,shuffle=True,drop_last = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ffmpeg\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as Func\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_map_dicts(path):\n",
    "        with open(path, 'rb') as fp:\n",
    "                return pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_PATH = '/home/anakuz/data/docs/iu_courses/dl_for_speech/hw3/II/mapping_dicts/train.p'\n",
    "DICT = open_map_dicts(DICT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_file = list(DICT.keys())[0]\n",
    "noisy_data = DICT[list(DICT.keys())[0]].split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(DICT_PATH, OUT_PATH):\n",
    "    \n",
    "    train_tups = []\n",
    "\n",
    "    for i in range(len(DICT)):\n",
    "        clean_file = list(DICT.keys())[i]\n",
    "        clean_speech, sr = librosa.load(clean_file,sr=None)\n",
    "\n",
    "        stft_clean = librosa.stft(clean_speech, n_fft=512,hop_length=160,win_length=320)\n",
    "        stft_clean = np.abs(stft_clean)\n",
    "\n",
    "        noisy_stfts = []\n",
    "        for p in noisy_data:\n",
    "            noisy_speech, sr = librosa.load(p ,sr=None)\n",
    "            stft_noisy = librosa.stft(noisy_speech, n_fft=512,hop_length=160,win_length=320)\n",
    "            stft_noisy = 10*np.log10(np.abs(stft_noisy))\n",
    "            noisy_stfts.append(stft_noisy)\n",
    "\n",
    "\n",
    "        for c in stft_clean.T:\n",
    "            for s in noisy_stfts:\n",
    "                for n in s.T:\n",
    "                    train_tups.append((c, n))\n",
    "    with open(OUT_PATH, 'wb') as f:\n",
    "        pickle.dump(train_tups, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainDataLoader(data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.dataFile = train_tups\n",
    "    def __getitem__(self, index):\n",
    "        X = self.dataFile[index][1]\n",
    "        M_truth = self.dataFile[index][0]\n",
    "        return torch.from_numpy(X),torch.from_numpy(M_truth)\n",
    "    def __len__(self):\n",
    "        #Number of files\n",
    "        return 641601 # CORRECT THIS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = data.DataLoader(trainDataLoader(),batch_size = 10000, shuffle=True,drop_last = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(257,1024)\n",
    "        self.fc2 = nn.Linear(1024,1024)\n",
    "        self.fc3 = nn.Linear(1024,1024)\n",
    "        self.fc4 = nn.Linear(1024,257)\n",
    "        \n",
    "    def forward(self,audio):\n",
    "        audio = Func.relu(self.fc1(audio))\n",
    "        audio = Func.relu(self.fc2(audio))\n",
    "        audio = Func.relu(self.fc3(audio))\n",
    "        audio = self.fc4(audio)\n",
    "        return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights(m):\n",
    "    if isinstance(m,nn.Linear):\n",
    "        nn.init.xavier_normal(m.weight.data)\n",
    "        nn.init.constant(m.bias.data,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anakuz/miniconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/anakuz/miniconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model.apply(weights)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-11850b76adea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \"\"\"\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \"\"\"\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m             raise RuntimeError(\n\u001b[1;32m    191\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.cuda()\n",
    "model = model.to(device)\n",
    "criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'trainDataLoader' object has no attribute 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a4d6808b683b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvali_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-5a3e6c36367a>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataFile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mM_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataFile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'trainDataLoader' object has no attribute 'self'"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "best_model = copy.deepcopy(model.state_dict())\n",
    "best_loss = 9999\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    loss = 0.0 \n",
    "    vali_loss = 0.0\n",
    "    for step, (audio, target) in enumerate(trainData): \n",
    "        audio = audio.to(device)\n",
    "        target = target.to(device)\n",
    "        model.train()\n",
    "        output = model(audio)\n",
    "        newLoss = criterion(output,target)\n",
    "        loss += newLoss.data\n",
    "        #print(step,loss)\n",
    "        optimizer.zero_grad()\n",
    "        newLoss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Train step:\"+str(step)+\"/\"+str(len(trainData)))\n",
    "    for step, (audio, target) in enumerate(valData): \n",
    "        audio = audio.to(device)\n",
    "        target = target.to(device)        \n",
    "        model.eval()\n",
    "        output = model(audio)\n",
    "        new_valiLoss = criterion(output,target)\n",
    "        vali_loss += new_valiLoss.data\n",
    "        #print(step,vali_loss)\n",
    "        if vali_loss < best_loss:\n",
    "                best_loss = vali_loss\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "        print(\"Valid step:\"+str(step)+\"/\"+str(len(valData)))\n",
    "    print('Epoch:{:2},Loss:{:>.5f}'.format(epoch,loss))\n",
    "    print('Epoch:{:2},Loss:{:>.5f}'.format(epoch,vali_loss)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
